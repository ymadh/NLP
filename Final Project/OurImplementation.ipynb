{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d51530a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.3.15-cp39-cp39-macosx_10_9_x86_64.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.9/288.9 KB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-macosx_10_11_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (3.0.12)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.2/895.2 KB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Installing collected packages: tokenizers, regex, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.5.1 regex-2022.3.15 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n",
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (3.17.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting numpy>=1.20\n",
      "  Downloading numpy-1.22.3-cp39-cp39-macosx_10_14_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (56.0.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.30.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (4.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.1.1)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.22.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.22.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5fb62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import InputExample, InputFeatures\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import TFDistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0fdc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "df = pd.read_json('Data/review_1000.json', lines=True)\n",
    "\n",
    "#get only the text\n",
    "#sentences = df.text.values\n",
    "\n",
    "#assigns positive of negative (words) to sentiment\n",
    "df[\"Sentiment\"] = df.stars.apply(lambda score: \"positive\" if score >= 3 else \"negative\")\n",
    "# change positive / negative to 1/ 0\n",
    "df['Sentiment'] = df['Sentiment'].map({'positive':1, 'negative':0})\n",
    "df['ratings'] = df.stars\n",
    "#just show the review and the new 1/0 \n",
    "df = df[[\"text\", \"Sentiment\", \"ratings\"]]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42315429",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df.text.values.tolist()\n",
    "labels = df.Sentiment.tolist()\n",
    "stars = df.ratings.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aef0d1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"If you decide to eat here, just be aware it is going to take about 2 hours from beginning to end. We have tried it multiple times, because I want to like it! I have been to it's other locations in NJ and never had a bad experience. \\n\\nThe food is good, but it takes a very long time to come out. The waitstaff is very young, but usually pleasant. We have just had too many experiences where we spent way too long waiting. We usually opt for another diner or restaurant on the weekends, in order to be done quicker.\", \"I've taken a lot of spin classes over the years, and nothing compares to the classes at Body Cycle. From the nice, clean space and amazing bikes, to the welcoming and motivating instructors, every class is a top notch work out.\\n\\nFor anyone who struggles to fit workouts in, the online scheduling system makes it easy to plan ahead (and there's no need to line up way in advanced like many gyms make you do).\\n\\nThere is no way I can write this review without giving Russell, the owner of Body Cycle, a shout out. Russell's passion for fitness and cycling is so evident, as is his desire for all of his clients to succeed. He is always dropping in to classes to check in/provide encouragement, and is open to ideas and recommendations from anyone. Russell always wears a smile on his face, even when he's kicking your butt in class!\"]\n",
      "[1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(reviews[:2])\n",
    "print(labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f5fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_sentences, validation_sentences, training_labels, validation_labels = train_test_split(reviews, labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "073e9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fede39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 15180, 3993, 2140, 999, 999, 999, 999, 2065, 1045, 2071, 2507, 5717, 2030, 4997, 3340, 1045, 2052, 999, 1045, 1005, 2310, 2196, 2626, 1037, 3319, 2077, 1010, 2021, 1045, 2572, 2183, 2041, 1997, 2026, 2126, 2000, 2360, 2008, 1045, 2018, 1996, 7619, 5409, 7759, 3325, 2012, 1996, 8739, 2160, 999, 999, 1998, 9686, 2361, 2945, 1010, 2994, 3154, 999, 2061, 2034, 2125, 1010, 1045, 2787, 2000, 2202, 2026, 2321, 3204, 2214, 2365, 2041, 2006, 1037, 10514, 6182, 3058, 1012, 2057, 7180, 2012, 1996, 8739, 2160, 2012, 1018, 9737, 1012, 2045, 2003, 2069, 2028, 2060, 2795, 1998, 2027, 2020, 5494, 2041, 1012, 2057, 4133, 2091, 1010, 1998, 1045, 3202, 3198, 2005, 1037, 3722, 3256, 2300, 2007, 14380, 1012, 15610, 3310, 2067, 2322, 2781, 2101, 1006, 2053, 2300, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([training_sentences[0]], truncation=True,\n",
    "                            padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feff31da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(training_sentences,\n",
    "                            truncation=True,\n",
    "                            padding=True)\n",
    "val_encodings = tokenizer(validation_sentences,\n",
    "                            truncation=True,\n",
    "                            padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e391d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 07:18:38.772714: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-15 07:18:38.772762: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-15 07:18:38.772783: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cet-herndon-jupyter): /proc/driver/nvidia/version does not exist\n",
      "2022-04-15 07:18:38.773093: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    training_labels\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    validation_labels\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0913165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 07:18:39.811764: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_layer_norm', 'vocab_transform', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_19', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0de835da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_sentences, validation_sentences, training_labels, validation_labels = train_test_split(reviews, labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "248e5334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ./sentiment were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at ./sentiment and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"./sentiment\")\n",
    "loaded_model = TFDistilBertForSequenceClassification.from_pretrained(\"./sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ae3bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "814\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "totalPos = 0\n",
    "totalNeg = 0\n",
    "\n",
    "for i in stars:\n",
    "    if (i >= 3):\n",
    "        totalPos = totalPos + 1\n",
    "    else: \n",
    "        totalNeg = totalNeg + 1\n",
    "# count the number of positives and negatives based on numbers\n",
    "print(len(reviews))\n",
    "print(totalPos)\n",
    "print(totalNeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "716eac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "441\n",
      "559\n"
     ]
    }
   ],
   "source": [
    "labelString = ['Negative','Positive']\n",
    "\n",
    "# test each review\n",
    "# middle_index=len(reviews)//2\n",
    "\n",
    "# first_half=reviews[:middle_index]\n",
    "# sec_half=reviews[middle_index:]\n",
    "# label_first_half = labels[:middle_index]\n",
    "# label_sec_half = labels[middle_index:]\n",
    "index = 0\n",
    "currPos = 0\n",
    "currNeg = 0\n",
    "for item1 in reviews:\n",
    "    # compare to item1 in second half\n",
    "    predict_input = tokenizer.encode(item1,\n",
    "                                 truncation=True,\n",
    "                                 padding=True,\n",
    "                                 return_tensors=\"tf\")\n",
    "   \n",
    "    tf_output = loaded_model.predict(predict_input)[0]\n",
    "    tf_prediction = tf.nn.softmax(tf_output, axis=1)\n",
    "    label = tf.argmax(tf_prediction, axis=1)\n",
    "    label = label.numpy()\n",
    "    \n",
    "    if (label[0] == 0):\n",
    "        currNeg = currNeg + 1\n",
    "    else:\n",
    "        currPos = currPos + 1\n",
    "    index = index + 1\n",
    "    \n",
    "\n",
    "print(index)\n",
    "print(currPos)\n",
    "print(currNeg)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097aa33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
