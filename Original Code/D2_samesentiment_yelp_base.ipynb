{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation - SameSentiment Yelp - Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers.trainer_utils import set_seed\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download + scp to server + extract\n",
    "data_yelp_path = Path(\"data/sentiment/yelp/\")\n",
    "\n",
    "# ------------------------------------\n",
    "\n",
    "# local?\n",
    "data_yelp_path = Path(\"data_raw/sentiment/yelp/\")\n",
    "\n",
    "# local? - output path (base) for sentiment review yelp pairs\n",
    "data_yelp_b_tdt_path = Path(\"data/sentiment/yelp-pair-b/\")\n",
    "data_yelp_b_rand_tdt_path = Path(\"data/sentiment/yelp-pair-rand-b/\")\n",
    "# local - output path for simple sentiment reviews yelp\n",
    "data_yelp_tdt_sentiment_5_path = Path(\"data/sentiment/yelp-sentiment-5/\")\n",
    "data_yelp_tdt_sentiment_b_path = Path(\"data/sentiment/yelp-sentiment-b/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_yelp_cached = data_yelp_path / \"cached\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #### Load categories & topics\n",
    "from data_prep import load_reviews, load_topics\n",
    "\n",
    "# ##### Filter categories\n",
    "from data_prep import filter_min_cat_combis, make_map_cats, make_cat_combis\n",
    "\n",
    "# ##### Filter reviews\n",
    "from data_prep import filter_min_review_freq, filter_both_good_bad\n",
    "\n",
    "# ##### Filter businesses\n",
    "from data_prep import filter_by_businesses, filter_by_businesses_not_same\n",
    "\n",
    "# #### Load category tree\n",
    "from data_prep import load_category_tree\n",
    "from data_prep import get_root_category_items, get_children_category_item_list\n",
    "from data_prep import get_businesses_in_category, get_businesses_in_category_branch\n",
    "\n",
    "\n",
    "# #### Cache root category reviews in dataframes\n",
    "from data_prep import cache_root_category_businesses_df, load_cached_root_category_businesses_df\n",
    "\n",
    "\n",
    "# #### Positive + negative same-sentiment pairs\n",
    "from data_prep import make_pairs_good_bad\n",
    "from data_prep import make_pairs_good_bad_over_business\n",
    "\n",
    "# #### Not same-sentiment pairs (combinations positive + negative)\n",
    "from data_prep import make_pairs_negative\n",
    "from data_prep import make_pairs_negative_over_business\n",
    "\n",
    "# #### Dataframe for training etc.\n",
    "from data_prep import make_or_load_pairs\n",
    "from data_prep import make_or_load_pairs_over_businesses\n",
    "\n",
    "\n",
    "# #### Make train/dev/test splits\n",
    "from data_prep import split_df, write_pair_df_tsv, write_pair_tdt_tsv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N positive + N negative\n",
    "# --> 2N pos+neg (not same-sentiment)\n",
    "num_pairs_per_class = 2\n",
    "\n",
    "#: number of negative same-sentiment samples same as positive same-sentiment samples\n",
    "num_pairs_negative = 2 * num_pairs_per_class\n",
    "\n",
    "#: whether for a single side (good or bad) there can be multiple occurrences of the same review\n",
    "#: may need to check afterwared that not by chance same pairing happens ...\n",
    "repeatable_on_side = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Test-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_yelp_df = data_yelp_path / \"df_traindev4_typed.p\"\n",
    "\n",
    "with open(fn_yelp_df, \"rb\") as fp:\n",
    "    traindev_df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_yelp_df = data_yelp_path / \"df_traindev_test.p\"\n",
    "#fn_yelp_df = data_yelp_path / \"df_traindev_test_over_business.p\"\n",
    "#traindev_df = df_traindev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traindev: [0:673099], test: [673099:747888], ratio: 0.1\n"
     ]
    }
   ],
   "source": [
    "# store\n",
    "traindev_df, test_df = split_df(traindev_df, ratio=0.1, do_shuffle=True, random_state=42, name_train=\"traindev\", name_dev=\"test\")\n",
    "\n",
    "with open(fn_yelp_df, \"wb\") as fp:\n",
    "    pickle.dump(traindev_df, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(test_df, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_yelp_df, \"rb\") as fp:\n",
    "    traindev_df = pickle.load(fp)\n",
    "    test_df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = data_yelp_b_tdt_path\n",
    "#root_path = data_yelp_b_rand_tdt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traindev: [0:605789], test: [605789:673099], ratio: 0.1\n",
      "train: [0:424052], dev: [424052:605789], ratio: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 424052/424052 [00:01<00:00, 215631.68it/s]\n",
      "dev: 100%|██████████| 181737/181737 [00:00<00:00, 216654.97it/s]\n",
      "test: 100%|██████████| 67310/67310 [00:00<00:00, 210823.98it/s]\n"
     ]
    }
   ],
   "source": [
    "write_pair_tdt_tsv(root_path, traindev_df, split_test=0.1, split_dev=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link 'data/sentiment/yelp-pair-b/pred.tsv': File exists\r\n"
     ]
    }
   ],
   "source": [
    "# symlink pred.tsv\n",
    "! ln -s test.tsv {root_path}/pred.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@  data/sentiment/yelp-pair-b \n",
      "\n",
      "total 774M\r\n",
      "-rw-r--r-- 1 jupyter-dunphya20 jupyter-dunphya20 209M Apr  3 16:05 dev.tsv\r\n",
      "lrwxrwxrwx 1 jupyter-dunphya20 jupyter-dunphya20    8 Apr  3 16:04 pred.tsv -> test.tsv\r\n",
      "-rw-r--r-- 1 jupyter-dunphya20 jupyter-dunphya20  78M Apr  3 16:05 test.tsv\r\n",
      "-rw-r--r-- 1 jupyter-dunphya20 jupyter-dunphya20 487M Apr  3 16:05 train.tsv\r\n"
     ]
    }
   ],
   "source": [
    "print(\"@ \", root_path, \"\\n\")\n",
    "! ls -lh {root_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"bert-base-cased\"\n",
    "model_name = \"distilroberta-base\"\n",
    "#model_name = \"distilbert-base-cased\"\n",
    "#model_name = \"albert-base-v2\"\n",
    "\n",
    "data_name = \"yelp-pair-b\"\n",
    "#data_name = \"yelp-pair-rand-b\" ## over businesses\n",
    "\n",
    "seq_len = 256\n",
    "batch_size = 16\n",
    "acc_steps = 64\n",
    "num_epoch = 3\n",
    "cuda_devs = \"1\"\n",
    "\n",
    "run_name = f\"{model_name.replace('/', '-')}-{data_name}_{seq_len}_{batch_size}-acc{acc_steps}_{num_epoch}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING|trainer.py:175] 04/03/2022 16:06:06 >> Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n",
      "[INFO|trainer.py:185] 04/03/2022 16:06:06 >> Training/evaluation parameters MyTrainingArguments(\n",
      "_n_gpu=0,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_test=True,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=64,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./output_sent/distilroberta-base-yelp-pair-b_256_16-acc64_3/runs/Apr03_16-06-06_cet-herndon-jupyter,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=5000,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=OptimizerNames.ADAMW_HF,\n",
      "output_dir=./output_sent/distilroberta-base-yelp-pair-b_256_16-acc64_3,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['mlflow', 'tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=distilroberta-base-yelp-pair-b_256_16-acc64_3,\n",
      "save_on_each_node=False,\n",
      "save_steps=10000,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=3,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "[INFO|trainer.py:186] 04/03/2022 16:06:06 >> Dataset parameters SamenessDataTrainingArguments(task_name='same-b', data_dir='./data/sentiment/yelp-pair-b', max_seq_length=256, overwrite_cache=False, pad_to_max_length=True)\n",
      "[INFO|trainer.py:187] 04/03/2022 16:06:06 >> Model parameters ModelArguments(model_name_or_path='distilroberta-base', config_name=None, tokenizer_name=None, cache_dir=None, use_fast_tokenizer=True)\n",
      "[INFO|configuration_utils.py:648] 2022-04-03 16:06:06,473 >> loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /home/jupyter-dunphya20/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n",
      "[INFO|configuration_utils.py:684] 2022-04-03 16:06:06,475 >> Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"distilroberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"same-b\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:344] 2022-04-03 16:06:06,614 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:648] 2022-04-03 16:06:06,737 >> loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /home/jupyter-dunphya20/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n",
      "[INFO|configuration_utils.py:684] 2022-04-03 16:06:06,739 >> Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"distilroberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1786] 2022-04-03 16:06:07,656 >> loading file https://huggingface.co/distilroberta-base/resolve/main/vocab.json from cache at /home/jupyter-dunphya20/.cache/huggingface/transformers/23e0f7484fc8a320856b168861166b48c2976bb4e0861602422e1b0c3fe5bf61.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "[INFO|tokenization_utils_base.py:1786] 2022-04-03 16:06:07,656 >> loading file https://huggingface.co/distilroberta-base/resolve/main/merges.txt from cache at /home/jupyter-dunphya20/.cache/huggingface/transformers/c7e8020011da613ff5a9175ddad64cd47238a9525db975eb50ecb965e9f7302f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1786] 2022-04-03 16:06:07,656 >> loading file https://huggingface.co/distilroberta-base/resolve/main/tokenizer.json from cache at /home/jupyter-dunphya20/.cache/huggingface/transformers/b6a9ca6504e67903474c3fdf82ba249882406e61c2176a9d4dc9c3691c663767.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "[INFO|tokenization_utils_base.py:1786] 2022-04-03 16:06:07,656 >> loading file https://huggingface.co/distilroberta-base/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1786] 2022-04-03 16:06:07,656 >> loading file https://huggingface.co/distilroberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1786] 2022-04-03 16:06:07,657 >> loading file https://huggingface.co/distilroberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:648] 2022-04-03 16:06:07,774 >> loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /home/jupyter-dunphya20/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n",
      "[INFO|configuration_utils.py:684] 2022-04-03 16:06:07,775 >> Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"distilroberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1431] 2022-04-03 16:06:08,024 >> loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /home/jupyter-dunphya20/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:1693] 2022-04-03 16:06:10,142 >> Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\r\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "[WARNING|modeling_utils.py:1704] 2022-04-03 16:06:10,142 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "[INFO|datasets.py:162] 04/03/2022 16:06:10 >> Creating features from dataset file at ./data/sentiment/yelp-pair-b\r\n"
     ]
    }
   ],
   "source": [
    "# create folder for logging\n",
    "! mkdir -p ./output_sent_logs/{run_name}\n",
    "\n",
    "! \\\n",
    "    MLFLOW_EXPERIMENT_NAME=same-sentiment \\\n",
    "    CUDA_VISIBLE_DEVICES={cuda_devs} \\\n",
    "    python trainer.py \\\n",
    "    --do_train --do_eval --do_test \\\n",
    "    --model_name_or_path {model_name} \\\n",
    "    --task_name same-b \\\n",
    "    --data_dir ./data/sentiment/{data_name} \\\n",
    "    --output_dir ./output_sent/{run_name} \\\n",
    "    --run_name {run_name} \\\n",
    "    --per_device_eval_batch_size {batch_size} \\\n",
    "    --per_device_train_batch_size {batch_size} \\\n",
    "    --gradient_accumulation_steps {acc_steps} \\\n",
    "    --logging_steps 5000 \\\n",
    "    --save_steps 10000 \\\n",
    "    --save_total_limit 3 \\\n",
    "    --num_train_epochs {num_epoch} \\\n",
    "    --max_seq_length {seq_len} \\\n",
    "    --evaluation_strategy epoch \\\n",
    "    > >(tee -a ./output_sent_logs/{run_name}/stdout.log) \\\n",
    "    2> >(tee -a ./output_sent_logs/{run_name}/stderr.log >&2)\n",
    "\n",
    "# --overwrite_output_dir \\\n",
    "# --overwrite_cache \\\n",
    "# --eval_steps 128 \\\n",
    "# --evaluation_strategy steps \\\n",
    "# --load_best_model_at_end \\\n",
    "# HF_MLFLOW_LOG_ARTIFACTS=TRUE \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train ...\n",
    "\n",
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=1 python trainer.py --do_train --do_eval --model_name_or_path bert-base-uncased --task_name same-b --data_dir ./data/sentiment/yelp-pair-b --output_dir ./output/yelp-pair-b_128_32_3 --run_name yelp-pair-b_128_32_3 --per_device_eval_batch_size 32 --per_device_train_batch_size 32 --logging_steps 10000 --save_steps 2000 --num_train_epochs 3 --max_seq_length 128\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test ...\n",
    "\n",
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=1 python trainer.py --do_test --model_name_or_path bert-base-uncased --task_name same-b --data_dir ./data/sentiment/yelp-pair-b --output_dir ./output/yelp-pair-b_128_32_3 --run_name yelp-pair-b_128_32_3 --per_device_eval_batch_size 32 --logging_steps 10000 --max_seq_length 128\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! CUDA_VISIBLE_DEVICES=0 python trainer.py --do_eval --do_test --model_name_or_path bert-base-uncased --task_name same-b --data_dir ./data/sentiment/yelp-pair-b --output_dir ./output/yelp-pair-b_128_32_3 --run_name yelp-pair-b_128_32_3 --per_device_eval_batch_size 32 --logging_steps 10000 --max_seq_length 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: **distilroberta-base**\n",
    "\n",
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=0 python trainer.py --do_train --do_eval --do_test --model_name_or_path distilroberta-base --task_name same-b --data_dir ./data/sentiment/yelp-pair-b --output_dir ./output/distilroberta-base-yelp-pair-b_128_32_3 --run_name distilroberta-base-yelp-pair-b_128_32_3 --per_device_eval_batch_size 32 --per_device_train_batch_size 32 --logging_steps 10000 --save_steps 2000 --num_train_epochs 3 --max_seq_length 128\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
