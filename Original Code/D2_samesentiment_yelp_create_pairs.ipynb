{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SameSentiment Yelp - Create Sentiment Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: collection in /home/jupyter-dunphya20/.local/lib/python3.9/site-packages (0.1.6)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/jupyter-dunphya20/.local/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/tljh/user/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/tljh/user/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/jupyter-dunphya20/.local/lib/python3.9/site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/tljh/user/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: networkx in /home/jupyter-dunphya20/.local/lib/python3.9/site-packages (2.7.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/jupyter-dunphya20/.local/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/tljh/user/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/tljh/user/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/jupyter-dunphya20/.local/lib/python3.9/site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/tljh/user/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install collection\n",
    "!pip install pandas\n",
    "!pip install networkx\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from itertools import combinations, groupby\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import networkx as nx\n",
    "except ImportError:\n",
    "    print(\"No networkx installed!\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers.trainer_utils import set_seed\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# download + scp to server + extract\n",
    "data_yelp_path = Path(\"data/sentiment/yelp/\")\n",
    "\n",
    "# ------------------------------------\n",
    "\n",
    "# local?\n",
    "data_yelp_path = Path(\"data_raw/sentiment/yelp/\")\n",
    "\n",
    "# local? - output path (base) for sentiment review yelp pairs\n",
    "data_yelp_b_tdt_path = Path(\"data/sentiment/yelp-pair-b/\")\n",
    "data_yelp_b_rand_tdt_path = Path(\"data/sentiment/yelp-pair-rand-b/\")\n",
    "# local - output path for simple sentiment reviews yelp\n",
    "data_yelp_tdt_sentiment_5_path = Path(\"data/sentiment/yelp-sentiment-5/\")\n",
    "data_yelp_tdt_sentiment_b_path = Path(\"data/sentiment/yelp-sentiment-b/\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_yelp_cached = data_yelp_path / \"cached\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #### Load categories & topics\n",
    "from data_prep import load_reviews, load_topics\n",
    "\n",
    "# ##### Filter categories\n",
    "from data_prep import filter_min_cat_combis, make_map_cats, make_cat_combis\n",
    "\n",
    "# ##### Filter reviews\n",
    "from data_prep import filter_min_review_freq, filter_both_good_bad\n",
    "\n",
    "# ##### Filter businesses\n",
    "from data_prep import filter_by_businesses, filter_by_businesses_not_same\n",
    "\n",
    "# #### Load category tree\n",
    "from data_prep import load_category_tree\n",
    "from data_prep import get_root_category_items, get_children_category_item_list\n",
    "from data_prep import get_businesses_in_category, get_businesses_in_category_branch\n",
    "\n",
    "\n",
    "# #### Cache root category reviews in dataframes\n",
    "from data_prep import cache_root_category_businesses_df, load_cached_root_category_businesses_df\n",
    "\n",
    "\n",
    "# #### Positive + negative same-sentiment pairs\n",
    "from data_prep import make_pairs_good_bad\n",
    "from data_prep import make_pairs_good_bad_over_business\n",
    "\n",
    "# #### Not same-sentiment pairs (combinations positive + negative)\n",
    "from data_prep import make_pairs_negative\n",
    "from data_prep import make_pairs_negative_over_business\n",
    "\n",
    "# #### Dataframe for training etc.\n",
    "from data_prep import make_or_load_pairs\n",
    "from data_prep import make_or_load_pairs_over_businesses\n",
    "\n",
    "\n",
    "# #### Make train/dev/test splits\n",
    "from data_prep import split_df, write_pair_df_tsv, write_pair_tdt_tsv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get topN categories + make Ntuples from category combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T09:52:22.837095Z",
     "start_time": "2020-05-25T09:52:22.827303Z"
    },
    "code_folding": [
     0,
     7
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_Ntop_cats(inv_cat_bids, n=50):\n",
    "    # get most common cats\n",
    "    f_cat_cnt = Counter({k: len(v) for k, v in inv_cat_bids.items()})\n",
    "    f_cats = {c for c, v in f_cat_cnt.most_common(n)}\n",
    "    return f_cats\n",
    "\n",
    "\n",
    "def make_cat_Ntuples(f_inv_cat_combis, n=2):\n",
    "    f_cat_pairs = Counter()\n",
    "\n",
    "    for cat_group in tqdm(f_inv_cat_combis.keys()):\n",
    "        if len(cat_group) < n:\n",
    "            continue\n",
    "        it = combinations(cat_group, n)\n",
    "        # repeat (#num_businesses) + chain combis\n",
    "        f_cat_pairs.update(it)\n",
    "        \n",
    "    return f_cat_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make category graph or NxN map (df + array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T09:52:24.807433Z",
     "start_time": "2020-05-25T09:52:24.793721Z"
    },
    "code_folding": [
     0,
     9
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_graph(f_cat_pairs):\n",
    "    g_from, g_to, g_value = zip(*((k1, k2, n) for (k1, k2), n in tqdm(f_cat_pairs.most_common())))\n",
    "\n",
    "    g_df = pd.DataFrame({\"from\": g_from, \"to\": g_to, \"value\": g_value})\n",
    "    G = nx.from_pandas_edgelist(g_df, \"from\", \"to\", create_using=nx.Graph())\n",
    "    \n",
    "    return G\n",
    "\n",
    "\n",
    "def make_NxN_map(f_cats, f_cat_pairs):\n",
    "    f_cats = list(f_cats)\n",
    "    array = list()\n",
    "    for i, cat1 in enumerate(tqdm(f_cats)):\n",
    "        array_row = list()\n",
    "        for j, cat2 in enumerate(f_cats):\n",
    "            array_row.append(f_cat_pairs.get((cat1, cat2), f_cat_pairs.get((cat2, cat1), 0)))\n",
    "        array.append(array_row)\n",
    "    df_cm = pd.DataFrame(array, index=list(f_cats), columns=list(f_cats))\n",
    "    \n",
    "    # dataframe, NxN array + labels\n",
    "    return df_cm, array, f_cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print category trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T09:52:29.242019Z",
     "start_time": "2020-05-25T09:52:29.205730Z"
    },
    "code_folding": [
     0,
     19,
     49,
     85,
     106
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def print_category_tree(map_categories):\n",
    "    root_categories = get_root_category_items(map_categories)\n",
    "    \n",
    "    def _print_cat_list_rec(lst_cats, level=0):\n",
    "        for item in sorted(lst_cats, key=lambda x: x[\"title\"]):\n",
    "            if level:\n",
    "                print(\"  \" * level, end=\"\")\n",
    "            print(f\"\"\"{item[\"title\"]} [{item[\"alias\"]}]\"\"\", end=\"\")\n",
    "            if item[\"children\"]:\n",
    "                print(f\"\"\" [#{len(item[\"children\"])} children]\"\"\")\n",
    "            else:\n",
    "                print()\n",
    "            \n",
    "            children = get_children_category_item_list(map_categories, item[\"alias\"])\n",
    "            _print_cat_list_rec(children, level=level + 1)\n",
    "            \n",
    "    _print_cat_list_rec(root_categories, level=0)\n",
    "\n",
    "\n",
    "def print_category_tree_with_num_businesses(map_categories, inv_cat_bids):\n",
    "    root_categories = get_root_category_items(map_categories)\n",
    "    \n",
    "    def _print_cat_list_rec(lst_cats, level=0):\n",
    "        for item in sorted(lst_cats, key=lambda x: x[\"title\"]):\n",
    "            cur_line = \" .\" * 30\n",
    "            parts = list()\n",
    "\n",
    "            if level:\n",
    "                parts.append(\"  \" * level)\n",
    "            parts.append(f\"\"\"{item[\"title\"]} [{item[\"alias\"]}]\"\"\")\n",
    "            \n",
    "            str_len = sum(len(part) for part in parts)\n",
    "            print(\"\".join(part for part in parts), end=\"\")\n",
    "            print(cur_line[str_len:], end=\"\")\n",
    "            \n",
    "            if item[\"title\"] not in inv_cat_bids:\n",
    "                print(\" No businesses associated!\")\n",
    "            else:\n",
    "                print(f\"\"\" {len((inv_cat_bids[item[\"title\"]])):>5d} businesses\"\"\")\n",
    "            \n",
    "            children = get_children_category_item_list(map_categories, item[\"alias\"])\n",
    "            _print_cat_list_rec(children, level=level + 1)\n",
    "            \n",
    "            if level == 0:\n",
    "                print()\n",
    "            \n",
    "    _print_cat_list_rec(root_categories, level=0)\n",
    "    \n",
    "\n",
    "def print_category_tree_with_num_businesses_rec(map_categories, inv_cat_bids, map_cat_name2id):\n",
    "    root_categories = get_root_category_items(map_categories)\n",
    "    \n",
    "    def _print_cat_list_rec(lst_cats, level=0):\n",
    "        for item in sorted(lst_cats, key=lambda x: x[\"title\"]):\n",
    "            cur_line = \" .\" * 30\n",
    "            parts = list()\n",
    "\n",
    "            if level:\n",
    "                parts.append(\"  \" * level)\n",
    "            parts.append(f\"\"\"{item[\"title\"]} [{item[\"alias\"]}]\"\"\")\n",
    "            \n",
    "            str_len = sum(len(part) for part in parts)\n",
    "            print(\"\".join(part for part in parts), end=\"\")\n",
    "            print(cur_line[str_len:], end=\"\")\n",
    "            \n",
    "            businesses = get_businesses_in_category_branch(inv_cat_bids, item[\"title\"], map_categories, map_cat_name2id)\n",
    "            businesses_self = get_businesses_in_category(inv_cat_bids, item[\"title\"])\n",
    "            if not businesses:\n",
    "                print(\" No businesses associated!\")\n",
    "            else:\n",
    "                businesses = set(businesses)\n",
    "                print(f\"\"\" {len(businesses):>5d} businesses\"\"\", end=\"\")\n",
    "                if len(businesses) != len(businesses_self):\n",
    "                    print(f\"\"\" (self: {len(businesses_self)})\"\"\", end=\"\")\n",
    "                print()\n",
    "            \n",
    "            children = get_children_category_item_list(map_categories, item[\"alias\"])\n",
    "            _print_cat_list_rec(children, level=level + 1)\n",
    "            \n",
    "            if level == 0:\n",
    "                print()\n",
    "            \n",
    "    _print_cat_list_rec(root_categories, level=0)\n",
    "    \n",
    "    \n",
    "def print_category_tree_with_num_businesses_root(map_categories, inv_cat_bids, map_cat_name2id):\n",
    "    root_categories = get_root_category_items(map_categories)\n",
    "    \n",
    "    for item in sorted(root_categories, key=lambda x: x[\"title\"]):\n",
    "        cur_line = \" .\" * 25\n",
    "        parts = [f\"\"\"{item[\"title\"]} [{item[\"alias\"]}] \"\"\"]\n",
    "\n",
    "        str_len = sum(len(part) for part in parts)\n",
    "        print(\"\".join(part for part in parts), end=\"\")\n",
    "        print(cur_line[str_len:], end=\"\")\n",
    "\n",
    "        businesses = get_businesses_in_category_branch(inv_cat_bids, item[\"title\"], map_categories, map_cat_name2id)\n",
    "        businesses_self = get_businesses_in_category(inv_cat_bids, item[\"title\"])\n",
    "\n",
    "        businesses = set(businesses)\n",
    "        print(f\"\"\" {len(businesses):>5d} businesses\"\"\", end=\"\")\n",
    "        if len(businesses) != len(businesses_self):\n",
    "            print(f\"\"\" (self: {len(businesses_self)})\"\"\", end=\"\")\n",
    "        print()\n",
    "        \n",
    "\n",
    "def print_category_tree_with_num_businesses_root2(map_categories, inv_cat_bids, map_cat_name2id):\n",
    "    root_categories = get_root_category_items(map_categories)\n",
    "    for item in root_categories:\n",
    "        item[\"businesses\"] = get_businesses_in_category_branch(inv_cat_bids, item[\"title\"], map_categories, map_cat_name2id)\n",
    "        item[\"businesses_self\"] = get_businesses_in_category(inv_cat_bids, item[\"title\"])\n",
    "    \n",
    "    for item in sorted(root_categories, key=lambda x: len(set(x[\"businesses\"]))):\n",
    "        cur_line = \" .\" * 25\n",
    "        parts = [f\"\"\"{item[\"title\"]} [{item[\"alias\"]}] \"\"\"]\n",
    "\n",
    "        str_len = sum(len(part) for part in parts)\n",
    "        print(\"\".join(part for part in parts), end=\"\")\n",
    "        print(cur_line[str_len:], end=\"\")\n",
    "\n",
    "        businesses = item[\"businesses\"]\n",
    "        businesses_self = item[\"businesses_self\"]\n",
    "\n",
    "        businesses = set(businesses)\n",
    "        print(f\"\"\" {len(businesses):>5d} businesses\"\"\", end=\"\")\n",
    "        if len(businesses) != len(businesses_self):\n",
    "            print(f\"\"\" (self: {len(businesses_self)})\"\"\", end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make category comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T09:52:31.432925Z",
     "start_time": "2020-05-25T09:52:31.423857Z"
    },
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def print_2category_compare(inv_cat_bids, map_categories, map_cat_name2id, cat_name_i, cat_name_j):\n",
    "    businesses_i = get_businesses_in_category_branch(inv_cat_bids, cat_name_i, map_categories, map_cat_name2id)\n",
    "    businesses_j = get_businesses_in_category_branch(inv_cat_bids, cat_name_j, map_categories, map_cat_name2id)\n",
    "    \n",
    "    cat_name_i += \":\"\n",
    "    cat_name_j += \":\"\n",
    "    width = max(12, len(cat_name_i), len(cat_name_j))\n",
    "\n",
    "    print(f\"\"\"{cat_name_i:<{width}} {len(set(businesses_i)):>5d}\"\"\")\n",
    "    print(f\"\"\"{cat_name_j:<{width}} {len(set(businesses_j)):>5d}\"\"\")\n",
    "    print(f\"\"\"Both: {\"same:\":>{width - 6}} {len(set(businesses_i) & set(businesses_j)):>5d}\"\"\")\n",
    "    print(f\"\"\"{\"total:\":>{width}} {len(set(businesses_i) | set(businesses_j)):>5d}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N positive + N negative\n",
    "# --> 2N pos+neg (not same-sentiment)\n",
    "num_pairs_per_class = 2\n",
    "\n",
    "#: number of negative same-sentiment samples same as positive same-sentiment samples\n",
    "num_pairs_negative = 2 * num_pairs_per_class\n",
    "\n",
    "#: whether for a single side (good or bad) there can be multiple occurrences of the same review\n",
    "#: may need to check afterwared that not by chance same pairing happens ...\n",
    "repeatable_on_side = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_raw/sentiment/yelp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [00:00, 116476.10it/s]\n"
     ]
    }
   ],
   "source": [
    "print(data_yelp_path)\n",
    "fn_yelp_reviews = data_yelp_path / \"review.json\"\n",
    "df = load_reviews(fn_yelp_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load categories for businesses\n",
    "\n",
    "- business (id) with list of topics/categories\n",
    "- lookups (business -> categories, category -> businesses)\n",
    "- list of combinations (with amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150346it [00:01, 87415.52it/s]\n",
      "100%|██████████| 150243/150243 [00:00<00:00, 863633.43it/s]\n",
      "100%|██████████| 150243/150243 [00:00<00:00, 327395.25it/s]\n"
     ]
    }
   ],
   "source": [
    "fn_yelp_topics = data_yelp_path / \"business.json\"\n",
    "bids_not_cats = set()\n",
    "inv_bid_cats = load_topics(fn_yelp_topics, bids_not_cats=bids_not_cats)\n",
    "\n",
    "inv_cat_bids = make_map_cats(inv_bid_cats)\n",
    "\n",
    "inv_cat_combis = make_cat_combis(inv_bid_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load category tree\n",
    "\n",
    "- hierarchy of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_yelp_catgory_tree = data_yelp_path / \"all_category_list.json\"\n",
    "map_categories, map_cat_name2id, lst_root_categories = load_category_tree(fn_yelp_catgory_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Cache all root category businesses (reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create cache dir: data_raw/sentiment/yelp/cached\n",
      "Filter category Active Life [active] with 7687 businesses ...\n",
      "Filter category Arts & Entertainment [arts] with 5434 businesses ...\n",
      "Filter category Automotive [auto] with 10773 businesses ...\n",
      "Filter category Beauty & Spas [beautysvc] with 14292 businesses ...\n",
      "Filter category Bicycles [bicycles] with 5 businesses ...\n",
      "Filter category Education [education] with 1936 businesses ...\n",
      "Filter category Event Planning & Services [eventservices] with 9895 businesses ...\n",
      "Filter category Financial Services [financialservices] with 1487 businesses ...\n",
      "Filter category Food [food] with 27781 businesses ...\n",
      "Filter category Health & Medical [health] with 11890 businesses ...\n",
      "Filter category Home Services [homeservices] with 14368 businesses ...\n",
      "Filter category Hotels & Travel [hotelstravel] with 5857 businesses ...\n",
      "Filter category Local Flavor [localflavor] with 1604 businesses ...\n",
      "Filter category Local Services [localservices] with 11198 businesses ...\n",
      "Filter category Mass Media [massmedia] with 156 businesses ...\n",
      "Filter category Nightlife [nightlife] with 12281 businesses ...\n",
      "Filter category Pets [pets] with 3758 businesses ...\n",
      "Filter category Professional Services [professional] with 3270 businesses ...\n",
      "Filter category Public Services & Government [publicservicesgovt] with 1216 businesses ...\n",
      "Filter category Religious Organizations [religiousorgs] with 286 businesses ...\n",
      "Filter category Restaurants [restaurants] with 52268 businesses ...\n",
      "Filter category Shopping [shopping] with 24395 businesses ...\n"
     ]
    }
   ],
   "source": [
    "cache_root_category_businesses_df(df, inv_cat_bids, map_categories, map_cat_name2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of businesses total: 150243\n",
      "Number of reviews total: 3002\n"
     ]
    }
   ],
   "source": [
    "# number of businesses\n",
    "print(f\"Number of businesses total: {len(inv_bid_cats.keys())}\")\n",
    "# number of reviews (total)\n",
    "print(f\"Number of reviews total: {df.rid.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make train pairs (normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 467.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#ss (pos) 2\n",
      "#ss (neg) 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 594.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#nss 4\n",
      "#~ss 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "fn_yelp_df = data_yelp_path / \"df_traindev.p\"\n",
    "\n",
    "df = filter_min_review_freq(df, min_ratings=5)\n",
    "df = filter_both_good_bad(df)\n",
    "\n",
    "df_traindev = make_or_load_pairs(df, inv_cat_bids, str(fn_yelp_df), num_pairs_per_class=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make train pairs (double, typed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#ss (pos) 0\n",
      "#ss (neg) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#nss 0\n",
      "#~ss 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "fn_yelp_df = data_yelp_path / \"df_traindev4_typed.p\"\n",
    "\n",
    "df = filter_min_review_freq(df, min_ratings=8)\n",
    "df = filter_both_good_bad(df)\n",
    "\n",
    "df_traindev = make_or_load_pairs(df, inv_cat_bids, str(fn_yelp_df), num_pairs_per_class=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make pairs but ignore business id relationship\n",
    "\n",
    "(&rarr; pairs between different businesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m filter_min_review_freq(df, min_ratings\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m filter_both_good_bad(df)\n\u001b[0;32m----> 7\u001b[0m df_traindev \u001b[38;5;241m=\u001b[39m \u001b[43mmake_or_load_pairs_over_businesses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_cat_bids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfn_yelp_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NLP/shared/data_prep_sentiment_yelp.py:660\u001b[0m, in \u001b[0;36mmake_or_load_pairs_over_businesses\u001b[0;34m(df, inv_bid_cats, fn_yelp_df, random_state)\u001b[0m\n\u001b[1;32m    657\u001b[0m num_businesses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    658\u001b[0m num_pairs \u001b[38;5;241m=\u001b[39m num_businesses\n\u001b[0;32m--> 660\u001b[0m pairs_good, pairs_bad \u001b[38;5;241m=\u001b[39m \u001b[43mmake_pairs_good_bad_over_business\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_bid_cats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_pairs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#ss (pos)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(pairs_good))\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#ss (neg)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(pairs_bad))\n",
      "File \u001b[0;32m~/NLP/shared/data_prep_sentiment_yelp.py:487\u001b[0m, in \u001b[0;36mmake_pairs_good_bad_over_business\u001b[0;34m(df, inv_bid_cats, num_pairs_per_side)\u001b[0m\n\u001b[1;32m    484\u001b[0m pairs_bad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m    486\u001b[0m grouper \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoodness\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 487\u001b[0m reviews_good \u001b[38;5;241m=\u001b[39m \u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_group\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m reviews_bad \u001b[38;5;241m=\u001b[39m grouper\u001b[38;5;241m.\u001b[39mget_group(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# make pairings -- good ss\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:747\u001b[0m, in \u001b[0;36mBaseGroupBy.get_group\u001b[0;34m(self, name, obj)\u001b[0m\n\u001b[1;32m    745\u001b[0m inds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_index(name)\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inds):\n\u001b[0;32m--> 747\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(name)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(inds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis)\n",
      "\u001b[0;31mKeyError\u001b[0m: True"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "fn_yelp_df = data_yelp_path / \"df_traindev_over_business.p\"\n",
    "\n",
    "df = filter_min_review_freq(df, min_ratings=5)\n",
    "df = filter_both_good_bad(df)\n",
    "\n",
    "df_traindev = make_or_load_pairs_over_businesses(df, inv_cat_bids, str(fn_yelp_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Test-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_yelp_df = data_yelp_path / \"df_traindev4_typed.p\"\n",
    "\n",
    "with open(fn_yelp_df, \"rb\") as fp:\n",
    "    traindev_df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_yelp_df = data_yelp_path / \"df_traindev_test.p\"\n",
    "#fn_yelp_df = data_yelp_path / \"df_traindev_test_over_business.p\"\n",
    "#traindev_df = df_traindev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store\n",
    "traindev_df, test_df = split_df(traindev_df, ratio=0.1, do_shuffle=True, random_state=42, name_train=\"traindev\", name_dev=\"test\")\n",
    "\n",
    "with open(fn_yelp_df, \"wb\") as fp:\n",
    "    pickle.dump(traindev_df, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(test_df, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_yelp_df, \"rb\") as fp:\n",
    "    traindev_df = pickle.load(fp)\n",
    "    test_df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = data_yelp_b_tdt_path\n",
    "#root_path = data_yelp_b_rand_tdt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pair_tdt_tsv(root_path, traindev_df, split_test=0.1, split_dev=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symlink pred.tsv\n",
    "! ln -s test.tsv {root_path}/pred.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"@ \", root_path, \"\\n\")\n",
    "! ls -lh {root_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
