{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle-test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgGD0FN3wRDJVRiyH7rcZC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ymadh/NLP/blob/main/kaggle_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RZ0ZJYx_7Ma",
        "outputId": "9f8ed2ff-e0a0-441e-c2a8-0a3c492113e4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.63.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n"
      ],
      "metadata": {
        "id": "1-hVv8codIcy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "7AUgA1fddMAl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "V_hv3GPIdOEI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d yelp-dataset/yelp-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBynXdtndRNg",
        "outputId": "8ae320ed-46a0-49c8-9836-82ee7168c1af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading yelp-dataset.zip to /content\n",
            "100% 4.07G/4.07G [00:17<00:00, 258MB/s]\n",
            "100% 4.07G/4.07G [00:17<00:00, 248MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d cheedcheed/yelp-categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a11YouTWgQqg",
        "outputId": "4ffaec20-58a9-4185-d50b-7286cdfaa7d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading yelp-categories.zip to /content\n",
            "\r  0% 0.00/34.9k [00:00<?, ?B/s]\n",
            "\r100% 34.9k/34.9k [00:00<00:00, 28.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip yelp-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18nXpN6neW6h",
        "outputId": "9a717561-6671-40f8-a36e-cdf8bfb10e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  yelp-dataset.zip\n",
            "  inflating: Dataset_User_Agreement.pdf  \n",
            "  inflating: yelp_academic_dataset_business.json  \n",
            "  inflating: yelp_academic_dataset_checkin.json  \n",
            "  inflating: yelp_academic_dataset_review.json  "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip yelp-categories.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtW3zH1DgbNF",
        "outputId": "c50f0d9d-826c-444e-f6dd-9430d69f649e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  yelp-categories.zip\n",
            "  inflating: yelp_categories.json    \n",
            "  inflating: yelp_health_categories.clean.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!mkdir data/sentiment\n",
        "!mkdir data/sentiment/yelp\n",
        "!mkdir data_raw #not sure if we need this or if it neesd to be renamed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPnxIIYahIoP",
        "outputId": "f7274e54-4a75-4e62-98c4-e7b55689dd01"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘data/sentiment’: File exists\n",
            "mkdir: cannot create directory ‘data/sentiment/yelp’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv yelp* data/sentiment/yelp/."
      ],
      "metadata": {
        "id": "Qc8J68dge_mS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "YcNjc-vBc7A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7TiqGdAEfFi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "RZ2gIiT5531-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e4653f8-3683-4589-ac94-56e7257bad51"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 8.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 31.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgZbOlmA_Ved",
        "outputId": "7f513c4c-ea6f-4946-f803-8fb7442d11b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-3.0.0-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonlines) (3.10.0.2)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_prep_sentiment_yelp.py"
      ],
      "metadata": {
        "id": "Ni1vkBGO_Q84"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_prep.py"
      ],
      "metadata": {
        "id": "oaxHzgt__M8V"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "VDFw7jna5p1R",
        "outputId": "1946a84d-d7d6-435a-84a2-94634c98a64b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/sentiment/yelp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6990280it [01:30, 77250.97it/s]\n",
            "150346it [00:03, 46327.20it/s]\n",
            "100%|██████████| 150243/150243 [00:00<00:00, 545986.76it/s]\n",
            "100%|██████████| 150243/150243 [00:00<00:00, 318613.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create cache dir: data_raw/sentiment/yelp/cached\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d72a5bdd5529>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0mmap_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_cat_name2id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst_root_categories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_category_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_yelp_catgory_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m \u001b[0mcache_root_category_businesses_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_cat_bids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_cat_name2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;31m# number of businesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/data_prep_sentiment_yelp.py\u001b[0m in \u001b[0;36mcache_root_category_businesses_df\u001b[0;34m(df, inv_cat_bids, map_categories, map_cat_name2id)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdn_yelp_cached\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Create cache dir: {dn_yelp_cached}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mdn_yelp_cached\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mroot_category\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mroot_categories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36mmkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1271\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1273\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1274\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparents\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_raw/sentiment/yelp/cached'"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from copy import deepcopy\n",
        "from itertools import combinations, groupby\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import networkx as nx\n",
        "except ImportError:\n",
        "    print(\"No networkx installed!\")\n",
        "\n",
        "from tqdm import tqdm\n",
        "from transformers.trainer_utils import set_seed\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "# download + scp to server + extract\n",
        "data_yelp_path = Path(\"data/sentiment/yelp/\")\n",
        "\n",
        "# ------------------------------------\n",
        "\n",
        "# local?\n",
        "data_yelp_path = Path(\"data/sentiment/yelp/\")\n",
        "\n",
        "# local? - output path (base) for sentiment review yelp pairs\n",
        "data_yelp_b_tdt_path = Path(\"data/sentiment/yelp-pair-b/\")\n",
        "data_yelp_b_rand_tdt_path = Path(\"data/sentiment/yelp-pair-rand-b/\")\n",
        "# local - output path for simple sentiment reviews yelp\n",
        "data_yelp_tdt_sentiment_5_path = Path(\"data/sentiment/yelp-sentiment-5/\")\n",
        "data_yelp_tdt_sentiment_b_path = Path(\"data/sentiment/yelp-sentiment-b/\")\n",
        "\n",
        "dn_yelp_cached = data_yelp_path / \"cached\"\n",
        "\n",
        "#  #### Load categories & topics\n",
        "from data_prep import load_reviews, load_topics\n",
        "\n",
        "# ##### Filter categories\n",
        "from data_prep import filter_min_cat_combis, make_map_cats, make_cat_combis\n",
        "\n",
        "# ##### Filter reviews\n",
        "from data_prep import filter_min_review_freq, filter_both_good_bad\n",
        "\n",
        "# ##### Filter businesses\n",
        "from data_prep import filter_by_businesses, filter_by_businesses_not_same\n",
        "\n",
        "# #### Load category tree\n",
        "from data_prep import load_category_tree\n",
        "from data_prep import get_root_category_items, get_children_category_item_list\n",
        "from data_prep import get_businesses_in_category, get_businesses_in_category_branch\n",
        "\n",
        "\n",
        "# #### Cache root category reviews in dataframes\n",
        "from data_prep import cache_root_category_businesses_df, load_cached_root_category_businesses_df\n",
        "\n",
        "\n",
        "# #### Positive + negative same-sentiment pairs\n",
        "from data_prep import make_pairs_good_bad\n",
        "from data_prep import make_pairs_good_bad_over_business\n",
        "\n",
        "# #### Not same-sentiment pairs (combinations positive + negative)\n",
        "from data_prep import make_pairs_negative\n",
        "from data_prep import make_pairs_negative_over_business\n",
        "\n",
        "# #### Dataframe for training etc.\n",
        "from data_prep import make_or_load_pairs\n",
        "from data_prep import make_or_load_pairs_over_businesses\n",
        "\n",
        "\n",
        "# #### Make train/dev/test splits\n",
        "from data_prep import split_df, write_pair_df_tsv, write_pair_tdt_tsv\n",
        "\n",
        "def get_Ntop_cats(inv_cat_bids, n=50):\n",
        "    # get most common cats\n",
        "    f_cat_cnt = Counter({k: len(v) for k, v in inv_cat_bids.items()})\n",
        "    f_cats = {c for c, v in f_cat_cnt.most_common(n)}\n",
        "    return f_cats\n",
        "\n",
        "\n",
        "def make_cat_Ntuples(f_inv_cat_combis, n=2):\n",
        "    f_cat_pairs = Counter()\n",
        "\n",
        "    for cat_group in tqdm(f_inv_cat_combis.keys()):\n",
        "        if len(cat_group) < n:\n",
        "            continue\n",
        "        it = combinations(cat_group, n)\n",
        "        # repeat (#num_businesses) + chain combis\n",
        "        f_cat_pairs.update(it)\n",
        "        \n",
        "    return f_cat_pairs\n",
        "\n",
        "def make_graph(f_cat_pairs):\n",
        "    g_from, g_to, g_value = zip(*((k1, k2, n) for (k1, k2), n in tqdm(f_cat_pairs.most_common())))\n",
        "\n",
        "    g_df = pd.DataFrame({\"from\": g_from, \"to\": g_to, \"value\": g_value})\n",
        "    G = nx.from_pandas_edgelist(g_df, \"from\", \"to\", create_using=nx.Graph())\n",
        "    \n",
        "    return G\n",
        "\n",
        "\n",
        "def make_NxN_map(f_cats, f_cat_pairs):\n",
        "    f_cats = list(f_cats)\n",
        "    array = list()\n",
        "    for i, cat1 in enumerate(tqdm(f_cats)):\n",
        "        array_row = list()\n",
        "        for j, cat2 in enumerate(f_cats):\n",
        "            array_row.append(f_cat_pairs.get((cat1, cat2), f_cat_pairs.get((cat2, cat1), 0)))\n",
        "        array.append(array_row)\n",
        "    df_cm = pd.DataFrame(array, index=list(f_cats), columns=list(f_cats))\n",
        "    \n",
        "    # dataframe, NxN array + labels\n",
        "    return df_cm, array, f_cats\n",
        "\n",
        "\n",
        "def print_category_tree(map_categories):\n",
        "    root_categories = get_root_category_items(map_categories)\n",
        "    \n",
        "    def _print_cat_list_rec(lst_cats, level=0):\n",
        "        for item in sorted(lst_cats, key=lambda x: x[\"title\"]):\n",
        "            if level:\n",
        "                print(\"  \" * level, end=\"\")\n",
        "            print(f\"\"\"{item[\"title\"]} [{item[\"alias\"]}]\"\"\", end=\"\")\n",
        "            if item[\"children\"]:\n",
        "                print(f\"\"\" [#{len(item[\"children\"])} children]\"\"\")\n",
        "            else:\n",
        "                print()\n",
        "            \n",
        "            children = get_children_category_item_list(map_categories, item[\"alias\"])\n",
        "            _print_cat_list_rec(children, level=level + 1)\n",
        "            \n",
        "    _print_cat_list_rec(root_categories, level=0)\n",
        "\n",
        "\n",
        "def print_category_tree_with_num_businesses(map_categories, inv_cat_bids):\n",
        "    root_categories = get_root_category_items(map_categories)\n",
        "    \n",
        "    def _print_cat_list_rec(lst_cats, level=0):\n",
        "        for item in sorted(lst_cats, key=lambda x: x[\"title\"]):\n",
        "            cur_line = \" .\" * 30\n",
        "            parts = list()\n",
        "\n",
        "            if level:\n",
        "                parts.append(\"  \" * level)\n",
        "            parts.append(f\"\"\"{item[\"title\"]} [{item[\"alias\"]}]\"\"\")\n",
        "            \n",
        "            str_len = sum(len(part) for part in parts)\n",
        "            print(\"\".join(part for part in parts), end=\"\")\n",
        "            print(cur_line[str_len:], end=\"\")\n",
        "            \n",
        "            if item[\"title\"] not in inv_cat_bids:\n",
        "                print(\" No businesses associated!\")\n",
        "            else:\n",
        "                print(f\"\"\" {len((inv_cat_bids[item[\"title\"]])):>5d} businesses\"\"\")\n",
        "            \n",
        "            children = get_children_category_item_list(map_categories, item[\"alias\"])\n",
        "            _print_cat_list_rec(children, level=level + 1)\n",
        "            \n",
        "            if level == 0:\n",
        "                print()\n",
        "            \n",
        "    _print_cat_list_rec(root_categories, level=0)\n",
        "    \n",
        "\n",
        "def print_category_tree_with_num_businesses_rec(map_categories, inv_cat_bids, map_cat_name2id):\n",
        "    root_categories = get_root_category_items(map_categories)\n",
        "    \n",
        "    def _print_cat_list_rec(lst_cats, level=0):\n",
        "        for item in sorted(lst_cats, key=lambda x: x[\"title\"]):\n",
        "            cur_line = \" .\" * 30\n",
        "            parts = list()\n",
        "\n",
        "            if level:\n",
        "                parts.append(\"  \" * level)\n",
        "            parts.append(f\"\"\"{item[\"title\"]} [{item[\"alias\"]}]\"\"\")\n",
        "            \n",
        "            str_len = sum(len(part) for part in parts)\n",
        "            print(\"\".join(part for part in parts), end=\"\")\n",
        "            print(cur_line[str_len:], end=\"\")\n",
        "            \n",
        "            businesses = get_businesses_in_category_branch(inv_cat_bids, item[\"title\"], map_categories, map_cat_name2id)\n",
        "            businesses_self = get_businesses_in_category(inv_cat_bids, item[\"title\"])\n",
        "            if not businesses:\n",
        "                print(\" No businesses associated!\")\n",
        "            else:\n",
        "                businesses = set(businesses)\n",
        "                print(f\"\"\" {len(businesses):>5d} businesses\"\"\", end=\"\")\n",
        "                if len(businesses) != len(businesses_self):\n",
        "                    print(f\"\"\" (self: {len(businesses_self)})\"\"\", end=\"\")\n",
        "                print()\n",
        "            \n",
        "            children = get_children_category_item_list(map_categories, item[\"alias\"])\n",
        "            _print_cat_list_rec(children, level=level + 1)\n",
        "            \n",
        "            if level == 0:\n",
        "                print()\n",
        "            \n",
        "    _print_cat_list_rec(root_categories, level=0)\n",
        "    \n",
        "    \n",
        "def print_category_tree_with_num_businesses_root(map_categories, inv_cat_bids, map_cat_name2id):\n",
        "    root_categories = get_root_category_items(map_categories)\n",
        "    \n",
        "    for item in sorted(root_categories, key=lambda x: x[\"title\"]):\n",
        "        cur_line = \" .\" * 25\n",
        "        parts = [f\"\"\"{item[\"title\"]} [{item[\"alias\"]}] \"\"\"]\n",
        "\n",
        "        str_len = sum(len(part) for part in parts)\n",
        "        print(\"\".join(part for part in parts), end=\"\")\n",
        "        print(cur_line[str_len:], end=\"\")\n",
        "\n",
        "        businesses = get_businesses_in_category_branch(inv_cat_bids, item[\"title\"], map_categories, map_cat_name2id)\n",
        "        businesses_self = get_businesses_in_category(inv_cat_bids, item[\"title\"])\n",
        "\n",
        "        businesses = set(businesses)\n",
        "        print(f\"\"\" {len(businesses):>5d} businesses\"\"\", end=\"\")\n",
        "        if len(businesses) != len(businesses_self):\n",
        "            print(f\"\"\" (self: {len(businesses_self)})\"\"\", end=\"\")\n",
        "        print()\n",
        "        \n",
        "\n",
        "def print_category_tree_with_num_businesses_root2(map_categories, inv_cat_bids, map_cat_name2id):\n",
        "    root_categories = get_root_category_items(map_categories)\n",
        "    for item in root_categories:\n",
        "        item[\"businesses\"] = get_businesses_in_category_branch(inv_cat_bids, item[\"title\"], map_categories, map_cat_name2id)\n",
        "        item[\"businesses_self\"] = get_businesses_in_category(inv_cat_bids, item[\"title\"])\n",
        "    \n",
        "    for item in sorted(root_categories, key=lambda x: len(set(x[\"businesses\"]))):\n",
        "        cur_line = \" .\" * 25\n",
        "        parts = [f\"\"\"{item[\"title\"]} [{item[\"alias\"]}] \"\"\"]\n",
        "\n",
        "        str_len = sum(len(part) for part in parts)\n",
        "        print(\"\".join(part for part in parts), end=\"\")\n",
        "        print(cur_line[str_len:], end=\"\")\n",
        "\n",
        "        businesses = item[\"businesses\"]\n",
        "        businesses_self = item[\"businesses_self\"]\n",
        "\n",
        "        businesses = set(businesses)\n",
        "        print(f\"\"\" {len(businesses):>5d} businesses\"\"\", end=\"\")\n",
        "        if len(businesses) != len(businesses_self):\n",
        "            print(f\"\"\" (self: {len(businesses_self)})\"\"\", end=\"\")\n",
        "        print()\n",
        "\n",
        "def print_2category_compare(inv_cat_bids, map_categories, map_cat_name2id, cat_name_i, cat_name_j):\n",
        "    businesses_i = get_businesses_in_category_branch(inv_cat_bids, cat_name_i, map_categories, map_cat_name2id)\n",
        "    businesses_j = get_businesses_in_category_branch(inv_cat_bids, cat_name_j, map_categories, map_cat_name2id)\n",
        "    \n",
        "    cat_name_i += \":\"\n",
        "    cat_name_j += \":\"\n",
        "    width = max(12, len(cat_name_i), len(cat_name_j))\n",
        "\n",
        "    print(f\"\"\"{cat_name_i:<{width}} {len(set(businesses_i)):>5d}\"\"\")\n",
        "    print(f\"\"\"{cat_name_j:<{width}} {len(set(businesses_j)):>5d}\"\"\")\n",
        "    print(f\"\"\"Both: {\"same:\":>{width - 6}} {len(set(businesses_i) & set(businesses_j)):>5d}\"\"\")\n",
        "    print(f\"\"\"{\"total:\":>{width}} {len(set(businesses_i) | set(businesses_j)):>5d}\"\"\")\n",
        "\n",
        "# N positive + N negative\n",
        "# --> 2N pos+neg (not same-sentiment)\n",
        "num_pairs_per_class = 2\n",
        "\n",
        "#: number of negative same-sentiment samples same as positive same-sentiment samples\n",
        "num_pairs_negative = 2 * num_pairs_per_class\n",
        "\n",
        "#: whether for a single side (good or bad) there can be multiple occurrences of the same review\n",
        "#: may need to check afterwared that not by chance same pairing happens ...\n",
        "repeatable_on_side = False\n",
        "print(data_yelp_path)\n",
        "fn_yelp_reviews = data_yelp_path / \"yelp_academic_dataset_review.json\"\n",
        "df = load_reviews(fn_yelp_reviews)\n",
        "\n",
        "fn_yelp_topics = data_yelp_path / \"yelp_academic_dataset_business.json\"\n",
        "bids_not_cats = set()\n",
        "inv_bid_cats = load_topics(fn_yelp_topics, bids_not_cats=bids_not_cats)\n",
        "\n",
        "inv_cat_bids = make_map_cats(inv_bid_cats)\n",
        "\n",
        "inv_cat_combis = make_cat_combis(inv_bid_cats)\n",
        "\n",
        "fn_yelp_catgory_tree = data_yelp_path / \"yelp_categories.json\" #\"all_category_list.json\"\n",
        "map_categories, map_cat_name2id, lst_root_categories = load_category_tree(fn_yelp_catgory_tree)\n",
        "\n",
        "cache_root_category_businesses_df(df, inv_cat_bids, map_categories, map_cat_name2id)\n",
        "\n",
        "# number of businesses\n",
        "print(f\"Number of businesses total: {len(inv_bid_cats.keys())}\")\n",
        "# number of reviews (total)\n",
        "print(f\"Number of reviews total: {df.rid.count()}\")\n",
        "\n",
        "set_seed(42)\n",
        "fn_yelp_df = data_yelp_path / \"df_traindev.p\"\n",
        "\n",
        "df = filter_min_review_freq(df, min_ratings=5)\n",
        "df = filter_both_good_bad(df)\n",
        "\n",
        "df_traindev = make_or_load_pairs(df, inv_cat_bids, str(fn_yelp_df), num_pairs_per_class=2)\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "fn_yelp_df = data_yelp_path / \"df_traindev4_typed.p\"\n",
        "\n",
        "df = filter_min_review_freq(df, min_ratings=8)\n",
        "df = filter_both_good_bad(df)\n",
        "\n",
        "df_traindev = make_or_load_pairs(df, inv_cat_bids, str(fn_yelp_df), num_pairs_per_class=4)\n",
        "\n",
        "set_seed(42)\n",
        "fn_yelp_df = data_yelp_path / \"df_traindev_over_business.p\"\n",
        "\n",
        "df = filter_min_review_freq(df, min_ratings=5)\n",
        "df = filter_both_good_bad(df)\n",
        "\n",
        "df_traindev = make_or_load_pairs_over_businesses(df, inv_cat_bids, str(fn_yelp_df))\n",
        "\n",
        "fn_yelp_df = data_yelp_path / \"df_traindev4_typed.p\"\n",
        "\n",
        "with open(fn_yelp_df, \"rb\") as fp:\n",
        "    traindev_df = pickle.load(fp)\n",
        "\n",
        "fn_yelp_df = data_yelp_path / \"df_traindev_test.p\"\n",
        "\n",
        "traindev_df, test_df = split_df(traindev_df, ratio=0.1, do_shuffle=True, random_state=42, name_train=\"traindev\", name_dev=\"test\")\n",
        "\n",
        "with open(fn_yelp_df, \"wb\") as fp:\n",
        "    pickle.dump(traindev_df, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    pickle.dump(test_df, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open(fn_yelp_df, \"rb\") as fp:\n",
        "    traindev_df = pickle.load(fp)\n",
        "    test_df = pickle.load(fp)\n",
        "\n",
        "root_path = data_yelp_b_tdt_path\n",
        "#root_path = data_yelp_b_rand_tdt_path\n",
        "\n",
        "write_pair_tdt_tsv(root_path, traindev_df, split_test=0.1, split_dev=0.3)\n",
        "\n",
        "print('run.....')\n",
        "print('! ln -s test.tsv {root_path}/pred.tsv')\n",
        "print('! ls -lh {root_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oLAn8MhZ5qz6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}